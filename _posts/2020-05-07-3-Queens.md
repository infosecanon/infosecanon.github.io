---
layout: post
title: "3 Queens"
date: 2020-05-07
---

Recall that we cut mini data segments to setup the pipeline:
<a href="/assets/P1_dvwa_101619.csv">NIDS-AML</a>
<a href="/assets/friout_00095_20170707131431.csv">CICIDS2017</a>
<a href="/assets/botnet-capture-20110810-neris.csv">CTU-13</a>

I started to code the algorithms to analyze the datasets, but I'll leave further
digression for a later post. We will need more data to work with anyway. This post
 covers the trials to creating a primary, or queen, `.csv` of each dataset,
aggregated across files.

## Preprocessing
Using an Ubuntu 18.04 VM I installed CICFlowMeter but ran into issues with space.
The VM's 40Gb hard drive was quickly taken up by the OS and any pcaps of unusual size
(_The Princess Bride_ nod), so I spun up a VM with Ubuntu 20.04, doubled the hard
drive space and reinstalled CICFlowMeter (btw `$ sudo gradle execute` really was
 important) only to have it hang. Back to the VM with less space.

 With the space requirement I had to cut up `.pcaps` to < 5Gb. Kind of a PITA when
 there are 70gb pcaps... If you're hurting for space later make sure to check the
 vmware `.cache`, move any files to the trash, and empty the trash. 5Gb was a 'sweet
 spot', so to speak, with regards to maximizing the size of the `.pcap` to minimize
 the amount to process while also not causing CICFlowMeter to hang. It doesn't appear
 to appreciate bigger `.pcaps`.

 Once the pcaps were processed to `.csvs` and moved from the VM to the host, they
 needed to be assembled. I wrote a helper script to combine the `.csvs` into a
 single queen for each dataset. Placed in the same folder as the `.csvs` it reads
 each into a list before writing a `.csv` with the provided header.

 ```python
 import csv, os, glob, sys


 folder_path = '/Users/d/Python/CiscoAML/CICIDS'
 new_csv = 'cicids-queen.csv'
 combined_list = []
 header = ['Flow ID','Src IP','Src Port','Dst IP','Dst Port','Protocol','Timestamp','Flow Duration','Total Fwd Packet','Total Bwd packets','Total Length of Fwd Packet','Total Length of Bwd Packet','Fwd Packet Length Max','Fwd Packet Length Min','Fwd Packet Length Mean','Fwd Packet Length Std','Bwd Packet Length Max','Bwd Packet Length Min','Bwd Packet Length Mean','Bwd Packet Length Std','Flow Bytes/s','Flow Packets/s','Flow IAT Mean','Flow IAT Std','Flow IAT Max','Flow IAT Min','Fwd IAT Total','Fwd IAT Mean','Fwd IAT Std','Fwd IAT Max','Fwd IAT Min','Bwd IAT Total','Bwd IAT Mean','Bwd IAT Std','Bwd IAT Max','Bwd IAT Min','Fwd PSH Flags','Bwd PSH Flags','Fwd URG Flags','Bwd URG Flags','Fwd Header Length','Bwd Header Length','Fwd Packets/s','Bwd Packets/s','Packet Length Min','Packet Length Max','Packet Length Mean','Packet Length Std','Packet Length Variance','FIN Flag Count','SYN Flag Count','RST Flag Count','PSH Flag Count','ACK Flag Count','URG Flag Count','CWE Flag Count','ECE Flag Count','Down/Up Ratio','Average Packet Size','Fwd Segment Size Avg','Bwd Segment Size Avg','Fwd Bytes/Bulk Avg','Fwd Packet/Bulk Avg','Fwd Bulk Rate Avg','Bwd Bytes/Bulk Avg','Bwd Packet/Bulk Avg','Bwd Bulk Rate Avg','Subflow Fwd Packets','Subflow Fwd Bytes','Subflow Bwd Packets','Subflow Bwd Bytes','FWD Init Win Bytes','Bwd Init Win Bytes','Fwd Act Data Pkts','Fwd Seg Size Min','Active Mean','Active Std','Active Max','Active Min','Idle Mean','Idle Std','Idle Max','Idle Min','Label']

 #read in the csvs
 for filename in glob.glob(os.path.join(folder_path, '*.csv')):
     with open(filename, 'r') as f:
         reader = csv.reader(f)

         print("Reading in ", filename)

         for row in reader:
             # skip appending the headers to the list
             if 'Flow ID' in row:
                 continue
             else:
                 combined_list.append(row)


 #write to csv
 with open(new_csv, 'w') as csvfile:
     cwriter = csv.writer(csvfile)
     print("writing ", new_csv)
     cwriter.writerow(header)
     cwriter.writerows(combined_list)

 ```

## CTU-13 Queen

If you recall [CTU-13 Labeling](/assets/CTU-13-Labeling.html) from an earlier post
a notebook labels the malicious traffic based on the IP address `147.32.84.165`
according to a README stored with each file. Turns out the attacker IP is
_always_ that IP - so it's pretty beneficial that we remove the IP Src from the
feature list because that would be a dead giveaway for the algorithm (to say nothing
  of the overhead required to map an IP as it's a categorical feature).

It only took about 2 seconds to process a single flow. Welp. That was for an order
of ~10 Kb a file. Combined, about 157.8 Mb. Labeled, 156 Mb.

.pcap | .csv | labeled | queen
--- | --- | --- | ---
2 Gb compressed | 157.8 Mb | 156 Mb | 156 Mb*
\*(Heather you should check this number later...)

Pulling in a new queen to one of the algorithms: [KNN](/assets/KNN.html)

Notice that `Flow ID`, `Src IP`, `Dst IP`, `Protocol`, `Timestamp`, `Flow Bytes/s`,
and `Flow Packet/s` are removed features. The first four are categorical and would
require overhead to map, timestamp is temporal, and - for whatever reason - I removed
the last two because I didn't feel like hunting NaNs.

Label | Meaning | # Instances
--- | --- | ---
0 | Benign | 145378
1 | Malicious | 162717

Training for a different `k` value between `k = 1` and `k = 25` reflected a best
accuracy around 3?

This queen required 638 seconds, or about 10 minutes, to run. Not bad.

## CICIDS 2017 Queen
Unlike the CTU-13 dataset, the providers of the CICIDS dataset were nice enough
to give us files that were already processed with CICFlowMeter. That's super
convenient because a look at the file server tells me I don't want to download
and process these by hand if I don't have to:

<img src="/assets/size-of-cicids.png" width="1200">

With the `combine.py` script above I attempted to pull the queen into a notebook
but noticed the headers were messed up.

<img src="/assets/dup-header.png" width="1200">

I went crazy looking through both queens to determine if I had a logic error, etc.
It wasn't until I looked at the CICIDS processed data that I noticed the repeated
column. Both the `AO` and `BJ` columns reflected the same values.

<img src="/assets/webatks.png" width="1200">
<img src="/assets/friday-working-hours.png" width="1200">

After removing the `BJ` column from the source files and recombining, the queen
was easier to process:
[KNN-CICIDS](/assets/CICIDS-Processing-and-Queen.html)

The same features were dropped as the prior queen.

.pcap | .csv | labeled | queen
--- | --- | --- | ---
47.9 Gb | 1.2 Gb | 1.1 Gb | 798 Mb

Label | Meaning | # Instances
--- | --- | ---
0 | Benign | 2273097
1 | Malicious | 557647

I had some issues with utf-8 encoding with this dataset and some lingering headers
that were not caught by the `combine.py` script. To get around it I ended up
using `to_numeric` to force the cells to integers, dropping NaNs generated this way
and searching for the keyword 'Source' in the `Src Port` column to remove a missed
header.

Notice the large jump in training time - 5646 seconds, or about 94 minutes. In order
to test for `k = range(1,26)` we need to run `94 * 25 = 2,350 minutes` or about
`40 hours` of runtime. Going to need some support for that test. A run is currently
in progress.

## NIDS-AML Queen
_To be continued..._
